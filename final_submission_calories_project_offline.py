# -*- coding: utf-8 -*-
"""Final_Submission_Calories_Project-Offline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f7shX_GICnHg3USHQDIxZ51NfvYXgS3c

# **Group Five: Predicting Calories Burnt During a Workout Session**


## Introduction

In recent years, humans have become more conscious of the need to stay fit and healthy as it is generally perceived that an active lifestyle makes them less prone to sicknesses and diseases. With the popularity of fitness apps, users are increasingly interested in understanding the calories they burn during various activities. Currently, estimates are often generalized and do not account for individual-specific factors, such as age, weight, or gender, which affect calorie burn rate. The goal of this project is to create a personalized model that accurately predicts calories burned, providing users with insights tailored to their physical profiles and workout specifics.


## Problem Statement

To develop a machine learning regression model to predict the number of calories burned during workout sessions based on user-specific and workout specific attributes. This prediction can help users track  their fitness progress and optimize their workout routines.

## Use Case Statement

The machine learning model will predict calories burned per workout session by analyzing individual and activity characteristics. This prediction can be integrated into fitness applications, wearables, and health platforms, allowing users to monitor and adjust their routines.

## Data Source

The dataset for the project was sourced from an open-access database [Exercise Dataset](https://www.kaggle.com/code/pragathiputhran/calories-burnt-prediction/input?select=exercise.csv) and [Calories Dataset](https://www.kaggle.com/code/pragathiputhran/calories-burnt-prediction/input?select=calories.csv) and then merged [Merged_Dataset](https://github.com/odunayoabogunrin/calories_burnt_prediction/blob/main/Merged_Calories_Data.xlsx).

## Data Preprocessing

The collected data will undergo preprocessing to ensure its suitability for machine learning.This will involve handling missing values and outliers, normalizing numerical features and encoding categorical variables. Feature engineering will also be performedto create new variables that may enhance the model's predictive power.

## Model Development

The machine learning model will be developed using several regression algorithms such as linear regression and XGBoost Regressor. These algorithms will be evaluated and compared based on their prediction accuracy, using performance metrics like mean absolute error (MAE), root mean square error (RMSE), and R-squared (RÂ²).

# Data Preparation
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing relevant libraries to import the dataset and for exploratory data analysis**
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

df = pd.read_csv('Exercise.csv')
df.head()

"""The dataframe contains key features that will be relevant for the model.


*   The age, height and weight are key demographic and body composition factors that influences calorie burn.
*   Gender is a biological factor that affects energy expenditure.
*   The heart rate is a direct indicator of workout intensity and effort.
*   The body Temperature reflects metabolic rate and body exertion during exercise.
*   The total time spent on the exercising is proportional to calorie burn.
*   Calorie burnt during the exercise session which is the target column.

**Prepare Data**
"""

#Checking out the shape of the data set
df.shape

"""The dataframe has 15000 rows and 9 columns."""

# Obtaining more info on the data set
df.info()

"""The dataset has no null values"""

#Checking out the statistics of the columns in the dataframe
df.describe().T

"""## **Exploratory Data Analysis**"""

#Checking out the columns in the dataset
df.columns

#Assigning the numerical columns to a variable name; columns
columns = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']

#Creating a side by side box plot and histogram of the numerical columns to check for outliers and their distribution
fig, axes = plt.subplots(nrows=len(columns), ncols=2, figsize=(12, 4 * len(columns)))

for i, col in enumerate(columns):
  # Box plot
  sns.boxplot(y=df[col], ax=axes[i, 0])
  axes[i, 0].set_title(f'Box Plot of {col}')
  axes[i, 0].set_ylabel(col)

  # Histogram
  sns.histplot(df[col], ax=axes[i, 1], bins=30, kde=True)
  axes[i, 1].set_title(f'Histogram of {col}')

plt.tight_layout()
plt.show()

"""The height, weight, duration and heart rate columns are normally distributed while age and body temperature are non-normally distributed. Also, the target variable (Calories) is skewed. Hence, transformation will be needed to make all non-normally distributed columns to be normally distributed."""

#Creating a piechart of the gender in the dataframe

fig = plt.figure(figsize=(3,3))
ax = plt.subplot(111)

df["Gender"].value_counts(normalize= True).plot(kind='pie', ax=ax, autopct='%1.1f%%',  title="Distribution of Gender", legend=False, fontsize=10, colors=['lightblue', 'gray'])
plt.show();

"""The proportion of the male and female gender in the dataset are almost equal. Hence, both genders are well represented in the dataset."""

#Creating a heatmap to know the correlation of the features
plt.figure(figsize=(12, 6))
sns.heatmap(df[columns].corr(),fmt= '.2f', annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

#Obtaining the exact correlation co-efficient
df[columns].corr()

"""This analysis revealed notable instances of multicollinearity among several of the variables, which could affect the regression model.

In particular:

1. **Height and Weight** exhibited a very high correlation coefficient of **0.958**.

2. **Duration and Body_Temp** had a similarly high correlation of **0.903**, while **Duration and Heart_Rate** showed a correlation of **0.853**.

Given the significant multicollinearity observed, steps may need to be taken to mitigate its impact. Potential solutions include removing one variable from each highly correlated pair (e.g., retaining `Height` while excluding `Weight`) or applying dimensionality reduction techniques like Principal Component Analysis (PCA) to combine these correlated variables.

**Capping of the Outliers**
"""

# Interquartile range (IQR) capping for non-normally distributed columns: Age and Body_Temp
for col in ['Age', 'Body_Temp']:
  Q1 = df[col].quantile(0.25)
  Q3 = df[col].quantile(0.75)
  IQR = Q3 - Q1
  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR

  # Cap values above and below bounds
  df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
  df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])

from scipy.stats import zscore
# Z-score capping for normally distributed columns: Height, Weight, Duration, Heart_Rate
for col in ['Height', 'Weight', 'Duration', 'Heart_Rate']:
  z_scores = zscore(df[col])
  abs_z_scores = np.abs(z_scores)

  # Cap values above and below threshold using mean +- z_threshold * std
  z_threshold = 3
  df[col] = np.where(abs_z_scores > z_threshold, df[col].mean() + z_threshold * df[col].std(), df[col])
  df[col] = np.where(abs_z_scores > z_threshold, df[col].mean() - z_threshold * df[col].std(), df[col])

"""**Feature Construction**"""

# Height is converted from cm to meters and creating a new feature; body mass index (BMI)

df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2

#Confirming the creation of the new column; BMI
df["BMI"].head()

# Defining new age bins and corresponding labels for broader categories
age_bins = [0, 30, 60, 80]
age_labels = ['Young', 'Middle-aged', 'Old']

# Creating a new column 'Age Group' with these broader age categories
df['Age_Group'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)

#Confirming the creation of the Age_Group column
df[['Age', 'Age_Group']].head()

"""**Transformation of the target column; Calories**"""

#Creating a new column; log_calories which is the natural logarithm of the target column; calories
df['log_calories'] = np.log1p(df['Calories'])

#Creating a new column; Calories_sqrt which is the square root of the target column; calories
df['Calories_sqrt'] = np.sqrt(df['Calories'])

#Confirming the new columns have been added to the dataframe
df.columns

#Assigning columns 'log_calories' and  'Calories_sqrt' to a list named; columns
columns = ['log_calories', 'Calories_sqrt']

#Creating histograms of the 'log_calories' and  'Calories_sqrt' columns
plt.figure(figsize=(12, 5))
for i, col in enumerate(columns, 1):
    plt.subplot(1, 2, i)
    # Create subplots
    sns.histplot(df[col], bins=20, edgecolor='black', alpha=0.7, kde=True)
    plt.title(f'Histogram of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

"""The calories_sqrt column has a better distribution than log_calories. Hence, Calories_sqrt will be used as the target vector.

**Data Preparation**
"""

df.columns

#Creating the feature matrix; X and dropping leaky features and an irrelevant column; 'User_ID'
X = df.drop(['User_ID', 'Calories', 'log_calories', 'Calories_sqrt'], axis=1)

#Creating the target vector
y = df['Calories_sqrt']



X.columns

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(drop='first', sparse_output=False)

cat_encode = encoder.fit_transform(X[['Gender', 'Age_Group']])

cat_encode_df = pd.DataFrame(
    cat_encode, columns=encoder.get_feature_names_out(['Gender', 'Age_Group'])
)

X = pd.concat([X.drop(columns=['Gender', 'Age_Group']), cat_encode_df], axis = 1)

"""### Splitting"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### Scaling"""

from sklearn.preprocessing import StandardScaler

columns = ['Age', 'Height', 'Weight', 'Duration',
       'Heart_Rate', 'Body_Temp', 'BMI']

scaler = StandardScaler()

X_train[columns] = scaler.fit_transform(X_train[columns])

X_test[columns] = scaler.transform(X_test[columns])

"""### Model training"""

from sklearn.linear_model import LinearRegression, Ridge, Lasso

model = Ridge()

model.fit(X_train, y_train)

"""### Evaluate"""

from sklearn.metrics import mean_squared_error, r2_score

train_pred = model.predict(X_train)
test_pred = model.predict(X_test)

train_score = r2_score(train_pred, y_train)
test_score = r2_score(test_pred, y_test)

train_score, test_score

"""### Feature Importance"""

coefficient = model.coef_

feature_importance2 = pd.DataFrame({
    "Feature": X_train.columns,
    "Importance": coefficient
})

data = feature_importance2.sort_values(by= 'Importance', ascending=True)

plt.figure(figsize=(7, 4))
plt.barh(data['Feature'], data['Importance'])
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('Feature Importance')



"""### Saving the best performing model"""

#Importing the library that will be used to save the best-performing model

import pickle

# Saving the best-performing model to a file named "model"
with open ("ridge_model.pkl", "wb") as f:
    pickle.dump(model, f)

print('Model saved successfully')

model



