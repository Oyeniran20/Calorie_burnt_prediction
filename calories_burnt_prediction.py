# -*- coding: utf-8 -*-
"""Calories burnt prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vAm_onNRhisCszqLcjH_dQHa-EhRxZBD

# **Predicting Calories Burnt During a Workout Session**


##**Introduction**

In recent years, humans have become more conscious of the need to stay
fit and healthy as it is generally perceived that an active lifestyle makes
them less prone to sicknesses and diseases. With the popularity of fitness
apps, users are increasingly interested in understanding the calories they
burn during various activities. Currently, estimates are often generalized and
do not account for individual-specific factors, such as age, weight, or gender,
which affect calorie burn rate. The goal of this project is to create a
personalized model that accurately predicts calories burned, providing users with insights tailored to their physical profiles and workout specifics.


##**Problem Statement**

To develop a machine learning regression model to predict the number of
calories burned during workout sessions based on user-specific and workout specific attributes. This prediction can help users track  their fitness progress and optimize their workout routines.

##**Use Case Statement**

The machine learning model will predict calories burned per workout session
by analyzing individual and activity characteristics. This prediction can be
integrated into fitness applications, wearables, and health platforms, allowing
users to monitor and adjust their routines.

**Importing relevant libraries for the project**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

df = pd.read_csv('https://raw.githubusercontent.com/Oyeniran20/Machine-Learning/refs/heads/main/3.%20Classification%20-/Exercise.csv')
df.head()

"""**Prepare Data**

The dataframe contains key features that will be relevant for the model.


*   The age, height and weight are Key demographic and body composition factors that influences calorie burn.
*   Gender is a biological factor that affects energy expenditure.
*   The heart rate is a direct indicator of workout intensity and effort.
*   The body Temperature reflects metabolic rate and body exertion during exercise.
*   The total time spent on the exercising is proportional to calorie burn.
*   Calorie burnt during the exercise session which is the target column.
"""

#Checking out the shape of the data set
df.shape

"""The dataframe has 15000 rows and 9 columns."""

# Obtaining more info on the data set
df.info()

"""The dataset has no null values"""

df.describe().T

"""## **Exploratory Data Analysis**"""

#Checking out the columns in the dataset
df.columns

#Checking the columns with numerical colu
columns = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']

fig, axes = plt.subplots(nrows=len(columns), ncols=2, figsize=(12, 4 * len(columns)))

for i, col in enumerate(columns):
  # Box plot
  sns.boxplot(y=df[col], ax=axes[i, 0])
  axes[i, 0].set_title(f'Box Plot of {col}')
  axes[i, 0].set_ylabel(col)

  # Histogram
  sns.histplot(df[col], ax=axes[i, 1], bins=30, kde=True)
  axes[i, 1].set_title(f'Histogram of {col}')

plt.tight_layout()
plt.show()

"""The target variable (Calories) is skewed, that is not normally distributed. Transformation is need to make it normally distributed."""

plt.figure(figsize=(10, 6))
sns.heatmap(df[columns].corr(),fmt= '.2f', annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""This analysis revealed notable instances of multicollinearity among several of the variables, which could affect the regression model.

In particular:

1. **Height and Weight** exhibited a very high correlation coefficient of **0.958**.

2. **Duration and Body_Temp** had a similarly high correlation of **0.903**, while **Duration and Heart_Rate** showed a correlation of **0.853**.

Given the significant multicollinearity observed, steps may need to be taken to mitigate its impact. Potential solutions include removing one variable from each highly correlated pair (e.g., retaining `Height` while excluding `Weight`) or applying dimensionality reduction techniques like Principal Component Analysis (PCA) to combine these correlated variables.

**Capping of the Outliers**
"""

# IQR capping for non-normally distributed columns: Age and Body_Temp
for col in ['Age', 'Body_Temp']:
  Q1 = df[col].quantile(0.25)
  Q3 = df[col].quantile(0.75)
  IQR = Q3 - Q1
  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR

  # Cap values above and below bounds
  df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
  df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])

from scipy.stats import zscore
# Z-score capping for normally distributed columns: Height, Weight, Duration, Heart_Rate
for col in ['Height', 'Weight', 'Duration', 'Heart_Rate']:
  z_scores = zscore(df[col])
  abs_z_scores = np.abs(z_scores)

  # Cap values above and below threshold using mean +- z_threshold * std
  z_threshold = 3
  df[col] = np.where(abs_z_scores > z_threshold, df[col].mean() + z_threshold * df[col].std(), df[col])
  df[col] = np.where(abs_z_scores > z_threshold, df[col].mean() - z_threshold * df[col].std(), df[col])

"""**Feature Construction**"""

# Height is converted from cm to meters

df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2

# Define new age bins and corresponding labels for broader categories
age_bins = [0, 30, 60, 80]
age_labels = ['Young', 'Middle-aged', 'Old']

# Create a new column 'Age Group' with these broader age categories
df['Age_Group'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)

df[['Age', 'Age_Group']].head()

"""**Transformation of Target Columns (Calories)**"""

df['log_calories'] = np.log1p(df['Calories'])
df['Calories_sqrt'] = np.sqrt(df['Calories'])

df.columns

columns = ['log_calories', 'Calories_sqrt']

plt.figure(figsize=(12, 5))
for i, col in enumerate(columns, 1):
    plt.subplot(1, 2, i)  # Create subplots
    sns.histplot(df[col], bins=20, edgecolor='black', alpha=0.7, kde=True)
    plt.title(f'Histogram of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

"""**Data Preparation**"""

X = df.drop(['User_ID', 'Calories', 'log_calories', 'Calories_sqrt'], axis=1)
y = df['Calories_sqrt']

"""**Data Splitting**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder

train_inputs, test_inputs, train_target, test_target = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Encoder**"""

train_inputs.columns

encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')

train_inputs_encoded = encoder.fit_transform(train_inputs[['Gender', 'Age_Group']])
test_inputs_encoded = encoder.transform(test_inputs[['Gender', 'Age_Group']])

train_inputs_encoded = pd.DataFrame(train_inputs_encoded, columns=encoder.get_feature_names_out(['Gender', 'Age_Group']))
test_inputs_encoded = pd.DataFrame(test_inputs_encoded, columns=encoder.get_feature_names_out(['Gender', 'Age_Group']))

train_inputs = train_inputs.drop(['Gender', 'Age_Group'], axis=1).join(train_inputs_encoded)
test_inputs = test_inputs.drop(['Gender', 'Age_Group'], axis=1).join(test_inputs_encoded)



"""**Standard Scaler**"""

scaler = StandardScaler()

train_inputs[['Height', 'Weight']] = scaler.fit_transform(train_inputs[['Height', 'Weight']])
test_inputs[['Height', 'Weight']] = scaler.transform(test_inputs[['Height', 'Weight']])

train_inputs[['Duration', 'Heart_Rate', 'Body_Temp']] = scaler.fit_transform(train_inputs[['Duration', 'Heart_Rate', 'Body_Temp']])
test_inputs[['Duration', 'Heart_Rate', 'Body_Temp']] = scaler.transform(test_inputs[['Duration', 'Heart_Rate', 'Body_Temp']])

train_inputs[['Age']] = scaler.fit_transform(train_inputs[['Age']])
test_inputs[['Age']] = scaler.transform(test_inputs[['Age']])

"""**PCA**"""

from sklearn.decomposition import PCA

# Apply PCA to correlated groups
pca_physical = PCA(n_components=1)
pca_exertion = PCA(n_components=1)

train_inputs_physical = pca_physical.fit_transform(train_inputs[['Height', 'Weight']])
test_inputs_physical = pca_physical.transform(test_inputs[['Height', 'Weight']])

train_inputs_exertion = pca_exertion.fit_transform(train_inputs[['Duration', 'Heart_Rate', 'Body_Temp']])
test_inputs_exertion = pca_exertion.transform(test_inputs[['Duration', 'Heart_Rate', 'Body_Temp']])

# Combining the transformed features and the categorical features
train_inputs_pca = np.hstack([train_inputs[['Age']].values, train_inputs_physical, train_inputs_exertion, train_inputs_encoded.values])
test_inputs_pca = np.hstack([test_inputs[['Age']].values, test_inputs_physical, test_inputs_exertion, test_inputs_encoded.values])

# Fit the mode
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(train_inputs_pca, train_target)

# performance of the model
from sklearn.metrics import mean_squared_error, r2_score
train_pred = model.predict(train_inputs_pca)
test_pred = model.predict(test_inputs_pca)

lin_train_score = model.score(train_inputs_pca, train_target)
lin_test_score = model.score(test_inputs_pca, test_target)

print('Linear Regression Train: ',  lin_train_score)
print('Linear Regression Test: ',  lin_test_score)

pip install catboost

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from catboost import CatBoostRegressor
from sklearn.model_selection import GridSearchCV
import xgboost as xgb

def evaluate_models(models, train_inputs, train_target, test_inputs, test_target):

  model.fit(train_inputs, train_target)

  # Predict for train & test
  train_pred = model.predict(train_inputs)
  test_pred = model.predict(test_inputs)

  # Training Metrics
  train_metrics = {
      'MSE': mean_squared_error(train_target, train_pred),
      'RMSE': np.sqrt(mean_squared_error(train_target, train_pred)),
      'R2': r2_score(train_target, train_pred)
  }

  # Test Metrics
  test_metrics = {
      'MSE': mean_squared_error(test_target, test_pred),
      'RMSE': np.sqrt(mean_squared_error(test_target, test_pred)),
      'R2': r2_score(test_target, test_pred)
  }

  # return performance metrics
  return train_metrics, test_metrics

models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor(),
    'XGBoost': xgb.XGBRegressor(),
    'CatBoost': CatBoostRegressor(verbose=0)
}

# Store results for each model
train_results = {}
test_results = {}

# Evaluate each model
for model_name, model in models.items():
  train_metrics, test_metrics = evaluate_models(model, train_inputs_pca, train_target, test_inputs_pca, test_target)
  train_results[model_name] = train_metrics
  test_results[model_name] = test_metrics

train_results_df = pd.DataFrame(train_results).T
test_results_df = pd.DataFrame(test_results).T

train_results_df

test_results_df

model = CatBoostRegressor(verbose=0)

model.fit(train_inputs_pca, train_target)
test_pred = model.predict(test_inputs_pca)
score = model.score(test_inputs_pca, test_target)
score

"""Save & Load the Model"""

# storing the model
import pickle

with open('model.pkl', 'wb') as file:
  pickle.dump(model, file)

# load the model
with open('model.pkl', 'rb') as file:
  model = pickle.load(file)

model.predict(test_inputs_pca[0])

